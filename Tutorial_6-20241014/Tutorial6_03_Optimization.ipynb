{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><font size = \"10\"> Week 6 - Single Cell Electrophysiology<center>\n",
    "<center><font size = \"8\">Tutorial 03: Parameter Optimization<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"3\"><font color = \"blue\"> In this tutorial you will optimize the soma conductances of a ball and stick cell model.\n",
    "    \n",
    "<font size = \"3\"><font color = \"blue\">The main goal of the tutorial is that you understand what is an optimization and what are the steps of a genetic algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Parameter Optimization?\n",
    "<font size='3'>A fancy name for training the selection of parameter values, which are optimal in some desired sense (eg. minimize an objective function you choose over a dataset you choose)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Parameters to be optimized.\n",
    "\n",
    "<font size='3'>First we need to know what do we want to optimize. A parameter can be in two states: frozen and not frozen. When a parameter is frozen it has an exact value, otherwise it only has some bounds but the exact value is not known yet. In this tutorial we will focus on optimizing the parameters at the soma.\n",
    "    \n",
    "<font size='3'>Let's create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load usefull packages\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from neuron import h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sections\n",
    "soma = h.Section(name='soma')\n",
    "dend = h.Section(name='dend')\n",
    "\n",
    "# Topology\n",
    "dend.connect(soma(1))\n",
    "\n",
    "# Geometry (frozen parameters)\n",
    "soma.L = soma.diam = 12.6157 # µm\n",
    "dend.L = 200                 # µm\n",
    "dend.diam = 1                # µm\n",
    "h.define_shape() # Translate into 3D points.\n",
    "\n",
    "# Biophysics\n",
    "for sec in h.allsec():\n",
    "    sec.Ra = 100    # Axial resistance in Ohm * cm (frozen)\n",
    "    sec.cm = 1      # Membrane capacitance in micro Farads / cm^2 (frozen)\n",
    "\n",
    "# Insert active Hodgkin-Huxley current in the soma\n",
    "soma.insert('hh')\n",
    "for seg in soma:\n",
    "    seg.hh.gnabar = 0.25  # Sodium conductance in S/cm2. [0, 1] (NOT frozen)\n",
    "    seg.hh.gkbar = 0.1    # Potassium conductance in S/cm2. [0, 1] (NOT frozen)\n",
    "    seg.hh.gl = 0.0003    # Leak conductance in S/cm2 (fix)\n",
    "    seg.hh.el = -54.3     # Reversal potential in mV (fix)\n",
    "\n",
    "# Insert passive current in the dendrite\n",
    "dend.insert('pas')\n",
    "for seg in dend:\n",
    "    seg.pas.g = 0.001  # Passive conductance in S/cm2 (frozen)\n",
    "    seg.pas.e = -65    # Leak reversal potential mV (frozen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='3'>So in this case we only have two not-frozen or variable parameters: gnabar and gkbar.\n",
    "\n",
    "<font size='3'>In the code above we have already asigned default parameters to these variables. Let's see how the cell behaves under two different stimulations during a current clamp experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inject current steps into the soma\n",
    "stim_amp = [0.1, 0.5]\n",
    "\n",
    "# Define plots\n",
    "fig1, ax1 = plt.subplots(figsize=(15,3))\n",
    "ax1.set(xlabel = 't (ms)', ylabel = 'V (mV)')\n",
    "\n",
    "fig2, ax2 = plt.subplots(figsize=(15,3))\n",
    "ax2.set(xlabel = 't (ms)', ylabel = 'I (nA)')\n",
    "\n",
    "# Stimulation\n",
    "for sa in stim_amp:  \n",
    "    # Place a stimulation electrode in the middle of the soma\n",
    "    stim = h.IClamp(soma(0.5))         \n",
    "    stim.delay = 100   # stim delay (ms)\n",
    "    stim.dur = 50      # stim duration (ms)\n",
    "    stim.amp = sa      # stim amplitude (nA)    \n",
    "    # Initialize NEURON vectors to record time, voltage and current\n",
    "    # time vector\n",
    "    rec_t = h.Vector()\n",
    "    rec_t.record(h._ref_t)\n",
    "    # membrame potential vector\n",
    "    rec_v_soma = h.Vector()\n",
    "    rec_v_soma.record(soma(0.5)._ref_v)\n",
    "    # current\n",
    "    rec_i = h.Vector()\n",
    "    rec_i.record(stim._ref_i)\n",
    "\n",
    "    # Initialize and run a simulation\n",
    "    h.load_file('stdrun.hoc')\n",
    "    h.finitialize(-65)\n",
    "    h.continuerun(200)\n",
    "    \n",
    "    ax1.plot(rec_t, rec_v_soma)\n",
    "    ax2.plot(rec_t, rec_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='3'>We see that for stim_amp = 0.1 nA the cell fires one action potential, while if stim_amp = 0.5 nA the cell fires 5 Action potentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Optimize cell conductances through a genetic algorithm\n",
    "\n",
    "<font size='3'>Now, instead of asigning default values for the conductances, we will try to find the conductances that make our cell behavies as we want. We will find the optimal values by using a genetic algorithm (GA).\n",
    "\n",
    "<font size='3'>The GA is a method for solving both constrained and unconstrained optimization problems that is based on natural selection, the process that drives biological evolution. The genetic algorithm repeatedly modifies a population of individual solutions. At each step, the genetic algorithm selects individuals at random from the current population to be parents and uses them to produce the children for the next generation. Over successive generations, the population \"evolves\" toward an optimal solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='3'>Let's start from zero.\n",
    "\n",
    "<font size='5'><font color='red'>RESTART YOUR KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load usefull packages\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from neuron import h\n",
    "\n",
    "# Cretae ball and stick model\n",
    "# Create sections\n",
    "soma = h.Section(name='soma')\n",
    "dend = h.Section(name='dend')\n",
    "\n",
    "# Topology\n",
    "dend.connect(soma(1))\n",
    "# Geometry\n",
    "soma.L = soma.diam = 12.6157 # microns\n",
    "dend.L = 200                 # microns\n",
    "dend.diam = 1                # microns\n",
    "h.define_shape() # Translate into 3D points.\n",
    "\n",
    "# Biophysics\n",
    "for sec in h.allsec():\n",
    "    sec.Ra = 100    # Axial resistance in Ohm * cm\n",
    "    sec.cm = 1      # Membrane capacitance in micro Farads / cm^2\n",
    "\n",
    "# Insert active Hodgkin-Huxley current in the soma\n",
    "# Now we won't include the values for gkbar and gnabar\n",
    "soma.insert('hh')\n",
    "for seg in soma:\n",
    "    #seg.hh.gnabar = 0.25  # Sodium conductance in S/cm2. [0, 1]\n",
    "    #seg.hh.gkbar = 0.1  # Potassium conductance in S/cm2. [0, 1]\n",
    "    seg.hh.gl = 0.0003    # Leak conductance in S/cm2\n",
    "    seg.hh.el = -54.3     # Reversal potential in mV\n",
    "\n",
    "# Insert passive current in the dendrite\n",
    "dend.insert('pas')\n",
    "for seg in dend:\n",
    "    seg.pas.g = 0.001  # Passive conductance in S/cm2\n",
    "    seg.pas.e = -65    # Leak reversal potential mV\n",
    "    \n",
    "stim = h.IClamp(soma(0.5))         \n",
    "stim.delay = 10   # stim delay (ms)\n",
    "stim.dur = 50  # stim duration (ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import efel\n",
    "\n",
    "# Create a function of the simulation that will give us the result for the different population members\n",
    "def stimulation(amp, plot=False):\n",
    "   \n",
    "    stim.amp = amp    # stim amplitude (nA)    \n",
    "    # Initialize NEURON vectors to record time, voltage and current\n",
    "    # time vector\n",
    "    rec_t = h.Vector()\n",
    "    rec_t.record(h._ref_t)\n",
    "    # membrame potential vector\n",
    "    rec_v_soma = h.Vector()\n",
    "    rec_v_soma.record(soma(0.5)._ref_v)\n",
    "    # current\n",
    "    rec_i = h.Vector()\n",
    "    rec_i.record(stim._ref_i)\n",
    "\n",
    "    # Initialize and run a simulation\n",
    "    h.load_file('stdrun.hoc')\n",
    "    h.finitialize(-65)\n",
    "    h.continuerun(60)\n",
    "    \n",
    "    trace = {'T': rec_t, 'V': rec_v_soma, 'stim_start': [stim.delay], 'stim_end': [stim.delay + stim.dur]}\n",
    "    if plot:\n",
    "        plt.plot(rec_t, rec_v_soma)\n",
    "    feature_values = efel.getFeatureValues([trace], ['Spikecount'])[0]\n",
    "    \n",
    "    return feature_values\n",
    "\n",
    "# RUN to test\n",
    "feat = stimulation(0.5)\n",
    "print(feat['Spikecount'][0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create a starting random population\n",
    "\n",
    "<font size='3'>The first step will be to create a random population of [gnabar, gkbar], knowing that the values for both variables are between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "import efel\n",
    "\n",
    "\n",
    "def create_starting_population(gna_min, gna_max, gk_min, gk_max, pop_size):\n",
    "    # Set up an initial array of all zeros\n",
    "    return np.array(list(zip(\n",
    "        np.random.uniform(gna_min, gna_max, size=pop_size),\n",
    "        np.random.uniform(gk_min, gk_max, size=pop_size))))\n",
    "\n",
    "\n",
    "pop = create_starting_population(0, 1, 0, 1, 10)\n",
    "print (pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Calculate fitness of population\n",
    "\n",
    "<font size='3'>In GAs we refer to how good each individual in the population is as ‘fitness’. The calculate_fitness function will be the evaluation procedure you wish to apply in your algorithm. In this example we are going to return the negative absolute difference between the spike counts observed in a phenotype and the spike counts expected based on experiments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def individual_fitness(gene, goal1, stim_amp1, goal2, stim_amp2, plot=False):\n",
    "    gna = gene[0]\n",
    "    gk = gene[1]\n",
    "    # Introduce mechanisms in the ball and stick model\n",
    "    #soma.insert('hh')\n",
    "    for seg in soma:\n",
    "        seg.hh.gnabar = gna  # Sodium conductance in S/cm2. [0, 1]\n",
    "        seg.hh.gkbar = gk  # Potassium conductance in S/cm2. [0, 1]\n",
    "    fits = []\n",
    "    for g, st in zip([goal1, goal2], [stim_amp1, stim_amp2]):\n",
    "        spike_count = stimulation(st, plot=plot) \n",
    "        value = spike_count['Spikecount'][0]\n",
    "        fit = np.abs(g - value)\n",
    "        fits.append(-fit)\n",
    "    return np.mean(fits)\n",
    "\n",
    "def calculate_fitness(population, goal1, stim_amp1, goal2, stim_amp2):\n",
    "    return np.array([individual_fitness(individual, goal1, stim_amp1, goal2, stim_amp2)\n",
    "                     for individual in population])\n",
    "\n",
    "\n",
    "fit_score = calculate_fitness(pop, 1, 0.1, 5, 0.5)\n",
    "print(fit_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Choosing individuals breed\n",
    "<font size='3'>Genetic algorithms mimic biology in that the individuals with the best fitness scores are most likely to breed and pass on their genes. But we do not simply take all the best individuals from our population to breed, as this might risk getting stuck in a local optimum. Rather, we use a method that means better individuals are moire likely to breed, but low fitness individuals at times may be chosen to breed.\n",
    "\n",
    "<font size='3'> In this case, the probability of an individual to be chosen will be proportional to its score minus the worst score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_parents(population, scores):\n",
    "    probs = scores - scores.min() + 1e-10 # avoid div by 0 error when population is homogenous\n",
    "    probs /= probs.sum()\n",
    "    return population[\n",
    "        np.random.choice(\n",
    "            np.arange(len(population)),\n",
    "            size=(len(population)//2, 2),\n",
    "            p=probs)]\n",
    "\n",
    "parents = select_reproduction(pop, fit_score)\n",
    "parents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Producing children from parents – crossover\n",
    "\n",
    "<font size='3'>When two individuals are chosen, the next step is to produce ‘children’ from them. We produce these children by ‘crossover’ mix of their values. One ‘child’ will take the gnabar from parent 1 and gkbar from parent 2. The result is a mix of \"genes\" from each parent. The second ‘child’ will be the opposite of this.\n",
    "\n",
    "<font size='3'>It is possible to have more than one crossover point, but we will keep it simple and have a single crossover point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breed_by_crossover(parents):\n",
    "    out = []\n",
    "    for parent1, parent2 in parents:\n",
    "        child1 = [parent1[0], parent2[1]]\n",
    "        child2 = [parent2[0], parent1[1]]\n",
    "        out.append(child1)\n",
    "        out.append(child2)\n",
    "    return np.array(out)\n",
    "\n",
    "\n",
    "children = breed_by_crossover(parents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Random mutation of genes\n",
    "\n",
    "<font size='3'>In evolution sometimes genes are copied incorrectly. This change may be harmful or beneficial. We mimic this by having a certain probability of that a conductance (\"gene\") becomes switched.\n",
    "\n",
    "<font size='3'>Typically this probability is low (e.g. 0.005), though it can be made to be flexible (e.g. increase mutation rate if progress has stalled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomly_mutate_population(population, mutation_probability, mutation_size=0.1):  \n",
    "    mutates = np.random.uniform(0, 1, size=population.shape) < mutation_probability\n",
    "    population[mutates] += np.random.normal() * mutation_size\n",
    "    population = np.maximum(population, 0)\n",
    "\n",
    "    \n",
    "print(children)\n",
    "\n",
    "randomly_mutate_population(children, 0.75)\n",
    "print(children)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Putting it all together\n",
    "\n",
    "<font size='3'>We’ve defined all the functions we need. Now let’s put it all together.\n",
    "    \n",
    "Because our target and therefore score is discrete (integer), there are no soft gradients to guide the algorithm and it can be very unstable.\n",
    "That is why we do one thing extra here: we always keep the the top performing individual from the previous generations, a strategy termed \"Elitism\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set general parameters\n",
    "from tqdm import tqdm\n",
    "population_size = 10\n",
    "maximum_generation = 10\n",
    "\n",
    "gna_min = 0.0\n",
    "gna_max = 1\n",
    "gk_min = 0.0\n",
    "gk_max = 1\n",
    "mutation_rate = 0.5\n",
    "stim_amp1 = 0.1 # nA\n",
    "goal1 = 1 # 1 spikes is our goal\n",
    "stim_amp2 = 0.5 # nA\n",
    "goal2 = 5 # 5 spikes is our goal\n",
    "\n",
    "\n",
    "# RUN\n",
    "population = create_starting_population(gna_min, gna_max, gk_min, gk_max, population_size)\n",
    "pop_scores = calculate_fitness(population, goal1, stim_amp1, goal2, stim_amp2)\n",
    "top_performer = population[np.argmax(pop_scores)]    \n",
    "\n",
    "mean_scores = []\n",
    "best_scores = []\n",
    "for generation in tqdm(range(maximum_generation)):\n",
    "    parents = select_parents(population, pop_scores)\n",
    "    population = breed_by_crossover(parents)\n",
    "    randomly_mutate_population(population, mutation_rate)\n",
    "    # elitism!\n",
    "    population[0] = top_performer\n",
    "    pop_scores = calculate_fitness(population, goal1, stim_amp1, goal2, stim_amp2)\n",
    "    mean_scores.append(pop_scores.mean())\n",
    "    best_scores.append(pop_scores.max())\n",
    "    top_performer = population[np.argmax(pop_scores)]\n",
    "    \n",
    "\n",
    "# Plot progress\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(best_scores, label='best')\n",
    "plt.plot(mean_scores, label='mean')\n",
    "plt.legend()\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('negative mean absolute error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing is not a simple problem.\n",
    "\n",
    "<font size = \"3\">This is only a very simple example of what an optimization is, and it gave us many different solutions. Usually we will optimize many more parameters together with respect to many more electrophysiological features. This makes it a very complex task, and it will give us only few potential solutions. As this is such a big problem, there are dedicated libraries such as [BluePyOpt](https://github.com/BlueBrain/BluePyOpt) (read the docs [here](https://bluepyopt.readthedocs.io/en/latest/)). BluePyOpt is an extensible framework for data-driven model parameter optimisation that wraps and standardizes several existing open-source tools. It simplifies the task of creating and sharing these optimisations, and the associated techniques and knowledge.\n",
    "    \n",
    "Often, it is not possible to find a good solution for all the desired electrophysiological features, and you instead find a range of approximate solutions with different strengths and weaknesses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
